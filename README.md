**This is a work-in-progress. This is still in pre-alpha stage**

# Datascience Toolbox Bootcamp

A pragmatic 5 week program that 80% of companies can use to get their interns/new employees started with Data Science inside their organization. Also useful for beginners who want to get started by themselves.

* Learn to set up a useful datascience ecosystem.
* Pick up SQL and NoSQL solutions that you prefer or that your company uses.
* Learn common (and powerful) Machine Learning ecosystems in vogue today, and learn how to learn a new statical programming language quickly.
* Gain experience with hands-on projects that reinforces technologies and techniques learnt.
* Beginner-friendly and adaptible to different levels of beginner-experience levels.

However, this is not a detailed instruction manual. There are just enough hints (sometimes more) to make the activities interesting for the audience and help them master a series of increasingly difficult challenges. Most of the materials used here is curated from the web and freely available.

Activities in a week are centered around a topic/theme/technology stack. Only the first week is needed to get started. Rest of the weeks can be picked or left out based on requirements.

# Who uses this material?

In the past, this material was used in workshops I conducted. Currently, I am using them in a Big Data and Analytics course that I teach in, the Data Science team I lead, and the Data Science team I mentor.


# The curriculum

## Overview

* Statistical Programming Language: We start with R, and use it to learn the design patterns in statistical programming languages (which teaches us both how to learn a new language for statistical programming and how to use these patterns for effective statistical programming as well). Then we quickly move to learn Python as well. While the student may not need to use both these languages in the longer run, learning both of them in the beginning is useful.
* SQL and NoSQL: Setting up multiple SQL solutions (MySQL, PostgreSQL) is covered, and only one of them needs to be picked up. The rest of the curriculum is agnostic of the choice. NoSQL, however, refers to a diverse collection of solutions. No standardization like SQL is available, and as a result the curriculum is not agnostic of the choice of NoSQL db. We learn CRUD in mongodb and dynamoDB and then use them in various activities afterwards.
* Cloud: AWS (ec2, S3, dynamoDB, redshift) 

## Details

* Week 1: Basics
  * Setup the system
  * Learn R, Python
  * Learn a SQL database system (MySQL or PostgreSQL)
  * Learn a NoSQL database system (mongodb)
  * Small Projects

* Week 2: Supervised Machine Learning
  * Linear and Logistic Regression, Penalized Regression
  * Decision Trees, Random Forest, GBM and eXtreme Gradient Boosting
  * The Kaggle Titanic Competition
  * Twitter Sentiment Analysis
  * Ensembling in Practice

* Week 3: Into the Cloud
  * ec2 and S3
  * Going CLI
  * dynamoDB
  * redshift
  * Mock ETL with Airflow

* Week 4: Projects
  * Document Classification
  * Build a Recommender System
  * Analyzing the Analyzers (Analyzing Data Science job postings)
  * Setup an ML pipeline (caret vs mlr, scikit-learn)
  * Beat a Kaggle Champion!

* Week 5: Data Science in the Wild!
  * Visualization with Grammar of Graphics (ggplot2, bokeh)
  * Reports, Table and Charts: Sharing results
  * Create an ML api (flask)
  * Build a Dashboard (flask)
  * Reasoning about metrics

